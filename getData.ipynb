{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Data using NYT API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wharton S&P Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYT Data \n",
    "src: https://towardsdatascience.com/collecting-data-from-the-new-york-times-over-any-period-of-time-3e365504004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2020-10-01', '00:00:00'], ['2020-11-01', '00:00:00']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_in_range = []\n",
    "for i in range(2020, 2021, 4):\n",
    "    end = datetime.date(i,11,30)\n",
    "    start = end - relativedelta(months=2)\n",
    "    months_in_year = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %-m\").tolist()]\n",
    "    months_in_range.extend(months_in_year)\n",
    "months_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\smuke\\\\OneDrive\\\\Desktop\\\\NYTvMarket'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() # Make sure this is the root directory for your repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(date):\n",
    "    '''Sends a request to the NYT Archive API for given date.'''\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    month = str(int(date[0][5:7]))\n",
    "    url = base_url + '/' + date[0][0:4] + '/' + month + '.json?api-key=' + \"Jha8a5QFDpLMrDm53n5aXK4vAlt5d1Sf\"\n",
    "    print(url)\n",
    "    response = requests.get(url).json()\n",
    "    time.sleep(6)\n",
    "    return response\n",
    "\n",
    "\n",
    "def is_valid(article, date):\n",
    "    '''An article is only worth checking if it is in range, and has a headline.'''\n",
    "    is_in_range = date > start and date < end\n",
    "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
    "    return is_in_range and has_headline\n",
    "\n",
    "\n",
    "def parse_response(response):\n",
    "    '''Parses and returns response as pandas data frame.'''\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "        'doc_type': [],\n",
    "        'material_type': [],\n",
    "        'section': [],\n",
    "        'keywords': []}\n",
    "    \n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: # For each article, make sure it falls within our date range\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        if is_valid(article, date):\n",
    "            data['date'].append(date)\n",
    "            data['headline'].append(article['headline']['main']) \n",
    "            if 'section' in article:\n",
    "                data['section'].append(article['section_name'])\n",
    "            else:\n",
    "                data['section'].append(None)\n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            if 'type_of_material' in article: \n",
    "                data['material_type'].append(article['type_of_material'])\n",
    "            else:\n",
    "                data['material_type'].append(None)\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "    return pd.DataFrame(data) \n",
    "\n",
    "\n",
    "def get_data(dates):\n",
    "    '''Sends and parses request/response to/from NYT Archive API for given dates.'''\n",
    "    total = 0\n",
    "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
    "    if not os.path.exists('headlines'):\n",
    "        os.mkdir('headlines')\n",
    "    for date in dates:\n",
    "        print(date[5:7])\n",
    "        response = send_request(date)\n",
    "        df = parse_response(response)\n",
    "        total += len(df)\n",
    "        df.to_csv('headlines/' + date[0][0:4] + '-' + date[0][5:7] + '.csv', index=False)\n",
    "        print('Saving headlines/' + date[0][0:4] + '-' + date[1][5:7] + '.csv...')\n",
    "    print('Number of articles collected: ' + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: ['2020-10-01', '00:00:00'] to ['2020-11-01', '00:00:00']\n",
      "[]\n",
      "https://api.nytimes.com/svc/archive/v1//2020/10.json?api-key=Jha8a5QFDpLMrDm53n5aXK4vAlt5d1Sf\n",
      "Saving headlines/2020-:0.csv...\n",
      "[]\n",
      "https://api.nytimes.com/svc/archive/v1//2020/11.json?api-key=Jha8a5QFDpLMrDm53n5aXK4vAlt5d1Sf\n",
      "Saving headlines/2020-:0.csv...\n",
      "Number of articles collected: 10300\n"
     ]
    }
   ],
   "source": [
    "get_data(months_in_range)\n",
    "os.chdir('./headlines/')\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "combined_csv.to_csv( \"NYTData.csv\", index=False, encoding='utf-8-sig')\n",
    "try:\n",
    "    all_filenames.remove(\"NYTData.csv\")\n",
    "except ValueError:\n",
    "    print(\"Success\")\n",
    "for file in all_filenames:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\smuke\\\\OneDrive\\\\Desktop\\\\NYTvMarket'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
